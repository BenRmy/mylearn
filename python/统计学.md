# 统计学/数据分析/机器学习相关

## NumPy--维度数组与矩阵运算运算及数学函数库

NumPy(Numerical Python)是Python语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。NumPy 是一个运行速度非常快的数学库，主要用于数组计算，功能包含：

+ 一个强大的N维数组对象 ndarray
+ 广播功能函数
+ 整合 C/C++/Fortran 代码的工具
+ 线性代数、傅里叶变换、随机数生成等功能

NumPy通常与SciPy(Scientific Python)和Matplotlib(绘图库)一起使用，这种组合广泛用于替代MatLab，是一个强大的科学计算环境，有助于通过Python学习数据科学或者机器学习。SciPy是一个开源的Python算法库和数学工具包。SciPy 包含的模块有最优化、线性代数、积分、插值、特殊函数、快速傅里叶变换、信号处理和图像处理、常微分方程求解和其他科学与工程中常用的计算。Matplotlib是Python编程语言及其数值数学扩展包NumPy的可视化操作界面。

Ndarray对象:N 维数组对象，它是一系列同类型数据的集合，以0为下标开始进行集合中元素的索引。ndarray 对象是用于存放同类型元素的多维数组、ndarray中的每个元素在内存中都有相同存储大小的区域。创建一个ndarray只需调用NumPy的 array 函数即可：
numpy.array(object, dtype=None, copy=True, order=None, subok=False, ndmin=0)  
参数说明：

名称|描述
--:|--:
object|数组或嵌套的数列
dtype|数组元素的数据类型，可选
copy|对象是否需要复制，可选
order|创建数组的样式，C为行方向，F为列方向，A为任意方向（默认）
subok|默认返回一个与基类类型一致的数组
ndmin|指定生成数组的最小维度

```python
import numpy as np
a = np.array([[1,  2],  [3,  4]])
print(a)
```

除了底层方法构建还有以下几种方式：

numpy.empty：用来创建一个指定形状（shape）、数据类型（dtype）且未初始化的数组：
numpy.empty(shape, dtype = float, order = 'C')

参数说明：

名称|描述
--:|--:
shape|数组形状
dtype|数据类型，可选
order|有"C"和"F"两个选项,分别代表，行优先和列优先，在计算机内存中的存储元素的顺序

numpy.zeros：创建指定大小的数组，数组元素以 0 来填充：
numpy.zeros(shape, dtype = float, order = 'C')
参数说明同上。

numpy.ones：创建指定形状的数组，数组元素以 1 来填充：
numpy.ones(shape, dtype = None, order = 'C')

从已有的数组创建数组：  

numpy.asarray：类似numpy.array，但numpy.asarray参数只有三个，比 numpy.array 少两个：numpy.asarray(a, dtype = None, order = None)  

numpy.frombuffer：用于实现动态数组。接受buffer输入参数，以流的形式读入转化成ndarray 对象：numpy.frombuffer(buffer, dtype = float, count = -1, offset = 0)  
注意：buffer 是字符串的时候，Python3默认str是Unicode 类型，所以要转成bytestring，在原str前加上b。

参数说明：

名称|描述
--:|--:
buffer|可以是任意对象，会以流的形式读入
dtype|返回数组的数据类型，可选
count|读取的数据数量，默认为-1，读取所有数据
offset|取的起始位置，默认为0

numpy.fromiter：从可迭代对象中建立 ndarray 对象，返回一维数组：
numpy.fromiter(iterable, dtype, count=-1)

以数值范围来创建数组：

numpy.arange：使用arange函数创建数值范围并返回ndarray对象，函数格式如下：
umpy.arange(start, stop, step, dtype)

根据 start 与 stop 指定的范围以及 step 设定的步长，生成一个ndarray。  

numpy.linspace：用于创建一个一维数组，数组是一个等差数列构成的，格式如下：
np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)

参数说明：

名称|描述
--:|--:
start|序列的起始值
stop|序列的终止值，如果endpoint为true，该值包含于数列中
num|要生成的等步长的样本数量，默认为50
endpoint|该值为 ture 时，数列中中包含stop值，反之不包含，默认是True。
retstep|如果为 True 时，生成的数组中会显示间距，反之不显示。
dtype|ndarray 的数据类型

numpy.logspace：用于创建一个等比数列。格式如下：
np.logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None)

base 参数意思是取对数的时候 log 的下标。

数据类型：numpy支持的数据类型比Python内置的类型要多很多，基本上可以和C语言的数据类型对应上，其中部分类型对应为 Python 内置的类型。数据类型对象(dtype)是用来描述与数组对应的内存区域如何使用，这依赖如下几个方面：

+ 数据的类型（整数，浮点数或者 Python 对象）
+ 数据的大小（例如， 整数使用多少个字节存储）
+ 数据的字节顺序（小端法或大端法）
+ 在结构化类型的情况下，字段的名称、每个字段的数据类型和每个字段所取的内存块的部分
+ 如果数据类型是子数组，它的形状和数据类型

字节顺序是通过对数据类型预先设定"<"或">"来决定的。"<"意味着小端法(最小值存储在最小的地址，即低位组放在最前面)。">"意味着大端法(最重要的字节存储在最小的地址，即高位组放在最前面)。dtype 对象是使用以下语法构造的：
numpy.dtype(object, align, copy)

+ object - 要转换为的数据类型对象
+ align - 如果为 true，填充字段使其类似 C 的结构体
+ copy - 复制 dtype 对象 ，如果为 false，则是对内置数据类型对象的引用

数组属性：ndarray 对象属性有：

名称|说明
--:|--:
ndarray.ndim|秩，即轴（axis）的数量或维度的数量
ndarray.shape|数组的维度，对于矩阵，n 行 m 列
ndarray.size|数组元素的总个数，相当于 .shape 中 n*m 的值
ndarray.dtype|ndarray 对象的元素类型
ndarray.itemsize|ndarray 对象中每个元素的大小，以字节为单位
ndarray.flags|ndarray 对象的内存信息
ndarray.real|ndarray元素的实部
ndarray.imag|ndarray 元素的虚部
ndarray.data|包含实际数组元素的缓冲区，由于一般通过数组的索引获取元素，所以通常不需要使用这个属性

切片和索引：ndarray对象的内容可以通过索引或切片来访问和修改，与Python中list的切片操作一样。除了用整数和切片的索引外，数组可以由整数数组索引、布尔索引及花式索引。

整数数组索引：以下实例获取数组中(0,0)，(1,1)和(2,0)位置处的元素：

```python
import numpy as np

x = np.array([[1,  2],  [3,  4],  [5,  6]])
y = x[[0, 1, 2],  [0, 1, 0]]
print(y)
```

布尔索引：布尔索引通过布尔运算（如：比较运算符）来获取符合指定条件的元素的数组:

```python
import numpy as np

x = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11]])
print(x[x > 5])
```

花式索引：指的是利用整数数组进行索引。花式索引根据索引数组的值作为目标数组的某个轴的下标来取值。对于使用一维整型数组作为索引，如果目标是一维数组，那么索引的结果就是对应位置的元素；如果目标是二维数组，那么就是对应下标的行。花式索引跟切片不一样，它总是将数据复制到新数组中。传入顺序索引数组:

```python
import numpy as np

x = np.arange(32).reshape((8, 4))
print(x[[4, 2, 1, 7]])
```

传入倒序索引数组:

```python
import numpy as np

x = np.arange(32).reshape((8, 4))
print(x[[-4, -2, -1, -7]])
```

传入多个索引数组（要使用np.ix_）:

```python
import numpy as np

x = np.arange(32).reshape((8, 4))
print(x[np.ix_([1, 5, 7, 2], [0, 3, 1, 2])])
```

广播(Broadcast)：是 numpy 对不同形状(shape)的数组进行数值计算的方式，对数组的算术运算通常在相应的元素上进行。如果两个数组 a 和 b 形状相同，即满足 a.shape == b.shape，那么 a*b 的结果就是 a 与 b 数组对应位相乘。这要求维数相同，且各维度的长度相同。当运算中的 2 个数组的形状不同时，numpy 将自动触发广播机制。广播的规则:

+ 让所有输入数组都向其中形状最长的数组看齐，形状中不足的部分都通过在前面加1补齐。
+ 输出数组的形状是输入数组形状的各个维度上的最大值。
+ 如果输入数组的某个维度和输出数组的对应维度的长度相同或者其长度为1时，这个数组能够用来计算，否则出错。
+ 当输入数组的某个维度的长度为1时，沿着此维度运算时都用此维度上的第一组值。

对两个数组，分别比较他们的每一个维度（若其中一个数组没有当前维度则忽略），满足：

+ 数组拥有相同形状。
+ 当前维度的值相等。
+ 当前维度的值有一个是 1。

若条件不满足，抛出 "ValueError: frames are not aligned" 异常。

迭代数组：迭代器对象numpy.nditer提供了一种灵活访问一个或者多个数组元素的方式。迭代器最基本的任务的可以完成对数组元素的访问。控制遍历顺序：

+ for x in np.nditer(a, order='F'):Fortran order，即是列序优先；
+ for x in np.nditer(a.T, order='C'):C order，即是行序优先；

修改数组中元素的值：nditer对象有另一个可选参数op_flags。默认情况下，nditer将视待迭代遍历的数组为只读对象（read-only），为了在遍历数组的同时，实现对数组元素值得修改，必须指定read-write或者write-only的模式。示例：

```python
import numpy as np

a = np.arange(0, 60, 5)
a = a.reshape(3, 4)
for x in np.nditer(a, op_flags=['readwrite']):
    x[...] = 2*x
print(a)
```

使用外部循环：nditer类的构造器拥有flags参数，它可以接受下列值：

参数|描述
--:|--:
c_index|可以跟踪 C 顺序的索引
f_index|可以跟踪 Fortran 顺序的索引
multi-index|每次迭代可以跟踪一种索引类型
external_loop|给出的值是具有多个值的一维数组，而不是零维数组

广播迭代：如果两个数组是可广播的，nditer组合对象能够同时迭代它们。假设数组a的维度为3X4，数组b的维度为1X4，则使用以下迭代器（数组b被广播到a的大小）。示例：

```python
import numpy as np

a = np.arange(0, 60, 5)
a = a.reshape(3, 4)
b = np.array([1,  2,  3,  4], dtype=int)
for x, y in np.nditer([a, b]):
    print("%d:%d" % (x, y), end=", ")
```

数组操作

修改数组形状：

函数|描述
--:|--:
reshape|不改变数据的条件下修改形状
flat|数组元素迭代器
flatten|返回一份数组拷贝，对拷贝所做的修改不会影响原始数组
ravel|返回展开数组

翻转数组：

函数|描述
--:|--:
transpose|对换数组的维度
ndarray.T|和 self.transpose() 相同
rollaxis|向后滚动指定的轴
swapaxes|对换数组的两个轴

修改数组维度：

函数|描述
--:|--:
broadcast|产生模仿广播的对象
broadcast_to|将数组广播到新形状
expand_dims|扩展数组的形状
squeeze|从数组的形状中删除一维条目

连接数组：

函数|描述
--:|--:
concatenate|连接沿现有轴的数组序列
stack|沿着新的轴加入一系列数组。
hstack|水平堆叠序列中的数组（列方向）
vstack|竖直堆叠序列中的数组（行方向）

分割数组：

函数|描述
--:|--:
split|将一个数组分割为多个子数组
hsplit|将一个数组水平分割为多个子数组（按列）
vsplit|将一个数组垂直分割为多个子数组（按行）

数组元素的添加与删除：

函数|描述
--:|--:
resize|返回指定形状的新数组
append|将值添加到数组末尾
insert|沿指定轴将值插入到指定下标之前
delete|删掉某个轴的子数组，并返回删除后的新数组
unique|查找数组内的唯一元素

位运算："bitwise_" 开头的函数是位运算函数。NumPy 位运算包括以下几个函数：

函数|描述
--:|--:
bitwise_and|对数组元素执行位与操作
bitwise_or|对数组元素执行位或操作
invert|按位取反
left_shift|向左移动二进制表示的位
right_shift|向右移动二进制表示的位

字符串函数：

函数|描述
--:|--:
add()|对两个数组的逐个字符串元素进行连接
multiply()|返回按元素多重连接后的字符串
center()|居中字符串
capitalize()|将字符串第一个字母转换为大写
title()|将字符串的每个单词的第一个字母转换为大写
lower()|数组元素转换为小写
upper()|数组元素转换为大写
split()|指定分隔符对字符串进行分割，并返回数组列表
splitlines()|返回元素中的行列表，以换行符分割
strip()|移除元素开头或者结尾处的特定字符
join()|通过指定分隔符来连接数组中的元素
replace()|使用新字符串替换字符串中的所有子字符串
decode()|数组元素依次调用str.decode
encode()|数组元素依次调用str.encode

数学函数：

NumPy 包含大量的各种数学运算的函数，包括三角函数，算术运算的函数，复数处理函数等。  
其还包含算术函数（包含简单的加减乘除）、统计函数（用于从数组中查找最小元素，最大元素，百分位标准差和方差等）、排序函数、筛选函数等。

矩阵库(Matrix)：

NumPy中包含了一个矩阵库numpy.matlib，该模块中的函数返回的是一个矩阵，而不是ndarray对象。一个 的矩阵是一个由行（row）列（column）元素排列成的矩形阵列。矩阵里的元素可以是数字、符号或数学式。

+ numpy.matlib.empty()：返回一个新的空矩阵
+ numpy.matlib.zeros()：创建一个以 0 填充的矩阵
+ numpy.matlib.ones()：创建一个以 1 填充的矩阵
+ numpy.matlib.eye()：返回一个单位矩阵，对角线元素为 1，其他位置为零
+ numpy.matlib.identity()：返回给定大小的单位矩阵
+ numpy.matlib.rand()：创建一个给定大小的矩阵，数据是随机填充的

线性代数：NumPy 提供了线性代数函数库linalg，该库包含了线性代数所需的所有功能：

函数|描述
--:|--:
dot|两个数组的点积，即元素对应相乘。
vdot|两个向量的点积
inner|两个数组的内积
matmul|两个数组的矩阵积
determinant|数组的行列式
solve|求解线性矩阵方程
inv|计算矩阵的乘法逆矩阵

IO：Numpy可以读写磁盘上的文本数据或二进制数据。NumPy为ndarray对象引入了一个简单的文件格式：npy。npy文件用于存储重建ndarray所需的数据、图形、dtype 和其他信息。常用的 IO 函数有：

+ load()和save()函数是读写文件数组数据的两个主要函数，默认情况下，数组是以未压缩的原始二进制格式保存在扩展名为.npy的文件中。
+ savze()函数用于将多个数组写入文件，默认情况下，数组是以未压缩的原始二进制格式保存在扩展名为.npz的文件中。
+ loadtxt()和savetxt( 函数处理正常的文本文件(.txt 等)

## pandas--数据分析库

Pandas概述：

+ Pandas是Python的一个数据分析包，该工具为解决数据分析任务而创建。
+ Pandas纳入大量库和标准数据模型，提供高效的操作数据集所需的工具。
+ Pandas提供大量能快速便捷地处理数据的函数和方法。
+ Pandas是字典形式，基于NumPy创建，让NumPy为中心的应用变得更加简单。

数据结构：

+ Series：相当于一维数组
+ DataFrame：表格型数据结构，包含一组有序的列，每列可以是不同的值类型。DataFrame有行索引和列索引，可以看成由Series组成的字典。

生成数据表：

+ 首先导入pandas库，一般都会用到numpy库，所以先导入备用：

```python
import numpy as np  
import pandas as pd  
```

+ 导入CSV或者xlsx文件：

```python
df = pd.DataFrame(pd.read_csv('name.csv',header=1))
df = pd.DataFrame(pd.read_excel('name.xlsx'))
```

+ 用pandas创建数据表：

```python
df = pd.DataFrame(
    {"id": [1001, 1002, 1003, 1004, 1005, 1006],
     "date": pd.date_range('20130102', periods=6),
     "city": ['Beijing ', 'SH', ' guangzhou ', 'Shenzhen', 'shanghai', 'BEIJING '],
     "age": [23, 44, 54, 32, 34, 32],
     "category": ['100-A', '100-B', '110-A', '110-C', '210-A', '130-F'],
     "price": [1200, np.nan, 2133, 5433, np.nan, 4432]},
    columns=['id', 'date', 'city', 'category', 'age', 'price'])
```

数据表信息查看：

+ df.shape：维度查看  
+ df.info()：数据表基本信息（维度、列名称、数据格式、所占空间等）  
+ df.dtypes：每一列数据的格式  
+ df['B'].dtype：某一列格式  
+ df.isnull()：查看某一列空值  
+ df['B'].unique()：查看某一列的唯一值  
+ df.values ：查看数据表的值  
+ df.columns：查看列名称  
+ df.head()：默认前10行数据（也可输入行数）  
+ df.tail()：默认后10 行数据（也可输入行数）  

数据表清洗：

+ df.fillna(value=0)：用数字0填充空值
+ df['prince'].fillna(df['prince'].mean())：使用列prince的均值对NA进行填充
+ df['city']=df['city'].map(str.strip)：清除city字段的字符空格
+ df['city']=df['city'].str.lower()：大小写转换
+ df['price'].astype('int')：更改数据格式
+ df.rename(columns={'category': 'category-size'})：更改列名称
+ df['city'].drop_duplicates()：删除后出现的重复值
+ df['city'].drop_duplicates(keep='last')：删除先出现的重复值
+ df['city'].replace('sh', 'shanghai')：数据替换

数据预处理：

示例数据：

```python
df1 = pd.DataFrame(
    {"id": [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008],
     "gender": ['male', 'female', 'male', 'female', 'male', 'female', 'male', 'female'],
     "pay": ['Y', 'N', 'Y', 'Y', 'N', 'Y', 'N', 'Y', ],
     "m-point": [10, 12, 20, 40, 40, 40, 30, 20]})
```

数据表合并:  

df_inner=pd.merge(df,df1,how='inner')  # 匹配合并，交集  
df_left=pd.merge(df,df1,how='left')  # 左连接  
df_right=pd.merge(df,df1,how='right')  # 右连接  
df_outer=pd.merge(df,df1,how='outer')  #并集  
df_inner.set_index('id')  # 设置索引列  
df_inner.sort_index()    # 按照索引列排序  
df_inner.sort_values(by=['age'])   # 按照特定列的值排序  
df_inner['group'] = np.where(df_inner['price'] > 3000,'high','low')   # 如果prince列的值>3000，group列显示high，否则显示low  
df_inner.loc[(df_inner['city'] == 'beijing') & (df_inner['price'] >= 4000), 'sign']=1  # 对复合多个条件的数据进行分组标记  
pd.DataFrame((x.split('-') for x in df_inner['category']),index=df_inner.index,columns=['category','size']))  # 对category字段的值依次进行分列，并创建数据表，索引值为df_inner的索引列，列名称为category和size  
df_inner=pd.merge(df_inner,split,right_index=True, left_index=True)  # 将完成分裂后的数据表和原df_inner数据表进行匹配  

数据提取:主要用到的三个函数：loc,iloc和ix。

+ loc函数按标签值进行提取
+ iloc按位置进行提取
+ ix可以同时按标签和位置进行提取

按索引提取单行的数值：df_inner.loc[3]  
按索引提取区域行数值：df_inner.iloc[0:5]  
重设索引：df_inner.reset_index()  
设置日期为索引：df_inner=df_inner.set_index('date')  
提取4日之前的所有数据：df_inner[:'2013-01-04']
使用iloc按位置区域提取数据：df_inner.iloc[:3,:2] #冒号前后的数字不再是索引的标签名称，而是数据所在的位置，从0开始，前三行，前两列。  
适应iloc按位置单独提起数据：df_inner.iloc[[0,2,5],[4,5]] #提取第0、2、5行，4、5列  
使用ix按索引标签和位置混合提取数据：df_inner.ix[:'2013-01-03',:4] #2013-01-03号之前，前四列数据  
判断city列的值是否为北京：df_inner['city'].isin(['beijing'])  
判断city列里是否包含beijing和shanghai，然后将符合条件的数据提取出来：df_inner.loc[df_inner['city'].isin(['beijing','shanghai'])]  
提取前三个字符，并生成数据表：pd.DataFrame(category.str[:3])  

数据筛选:使用与、或、非三个条件配合大于、小于、等于对数据进行筛选，并进行计数和求和。  

使用“与”进行筛选：df_inner.loc[(df_inner['age'] > 25) & (df_inner['city'] == 'beijing'), ['id','city','age','category','gender']]  
使用“或”进行筛选：df_inner.loc[(df_inner['age'] > 25) | (df_inner['city'] == 'beijing'), ['id','city','age','category','gender']].sort(['age'])  
使用“非”条件进行筛选：df_inner.loc[(df_inner['city'] != 'beijing'), ['id','city','age','category','gender']].sort(['id'])  
对筛选后的数据按city列进行计数：df_inner.loc[(df_inner['city'] != 'beijing'), ['id','city','age','category','gender']].sort(['id']).city.count()  
使用query函数进行筛选：df_inner.query('city == ["beijing", "shanghai"]')  
对筛选后的结果按prince进行求和：df_inner.query('city == ["beijing", "shanghai"]').price.sum()

数据汇总:主要函数是groupby和pivote_table。  

对所有的列进行计数汇总：df_inner.groupby('city').count()  
按城市对id字段进行计数：
```df_inner.groupby('city')['id'].count()```
对两个字段进行汇总计数：
```df_inner.groupby(['city','size'])['id'].count()```
对city字段进行汇总，并分别计算prince的合计和均值：
```df_inner.groupby('city')['price'].agg([len,np.sum, np.mean])```

数据统计:主要是数据采样，计算标准差，协方差和相关系数。  

简单的数据采样：df_inner.sample(n=3)  
手动设置采样权重：  
weights = [0, 0, 0, 0, 0.5, 0.5]  
df_inner.sample(n=2, weights=weights)  
采样后不放回：df_inner.sample(n=6, replace=False)  
采样后放回：df_inner.sample(n=6, replace=True)  
数据表描述性统计：df_inner.describe().round(2).T #round函数设置显示小数位，T表示转置  
计算列的标准差：df_inner['price'].std()  
计算两个字段间的协方差：df_inner['price'].cov(df_inner['m-point'])  
数据表中所有字段间的协方差：df_inner.cov()  
两个字段的相关性分析：df_inner['price'].corr(df_inner['m-point']) #相关系数在-1到1之间，接近1为正相关，接近-1为负相关，0为不相关  
数据表的相关性分析：df_inner.corr()

数据输出：分析后的数据可以输出为xlsx格式和csv格式。  

写入Excel：df_inner.to_excel('excel_to_python.xlsx', sheet_name='bluewhale_cc')

写入到CSV：df_inner.to_csv('excel_to_python.csv')
